# Корутины на архитектуре Эльбрус (e2k)

## Введение

В данной заметке мы рассмотрим особый вид функций, так называемые
корутины. О корутинах уже написан солидный ряд статей. Но мы обсудим
проблемы корутин в свете архитектуры Эльбрус.

Корутины или сопрограммы(coroutines) были введены в C++20. Обычно они
используются либо в качестве генераторов, либо для асинхронного
программирования. Корутина - это функция, которая может
приостанавливать и возобновлять свое выполнение, сохраняя при этом свое
состояние. Корутины делятся на два типа - *stackful* и *stackless*. Первые
имеют свой стек, их выполнение управляется кодом, они не зависят от
операционной системы. Вторые не используют собственный стек, хотя и
живут на стеке вызывающей функции: они приостанавливают выполнение,
возвращаясь к вызывающей функции, а данные, необходимые для
возобновления выполнения, хранятся отдельно от стека. Оба вида корутин
позволяют создавать последовательный код, выполняющийся асинхронно
(например, для обработки неблокирующего ввода-вывода без коллбэков), а
также поддерживает алгоритмы для лениво вычисляемых бесконечных
последовательностей и другие варианты использования.

На популярных архитектурах, таких как x86-64 или ARM, их реализация
опирается на относительно простую и хорошо документированную модель
стека и сохранения контекста выполнения. Однако при переносе подобных
механизмов на архитектуру Эльбрус разработчик быстро сталкивается с тем,
что многие привычные допущения, такие как наличие единственного
линейного стека в памяти, возможность явного сохранения регистров
инструкциями push/pop и представление полного контекста выполнения в
виде набора данных в памяти перестают работать.

Цель наших рассуждений - выяснить, какие именно особенности
архитектуры e2k влияют на реализацию корутин, почему возникают проблемы
и что с этим делать.

### Особый случай

Использование корутин на e2k является особым случаем по ряду причин.
Во-первых, архитектура Эльбрус относится к категории архитектур,
использующих принцип широкого командного слова (*Very Large Instruction
Word*, *VLIW*), когда компилятор формирует для параллельного исполнения
последовательности групп команд (широкие командные слова), в которых
отсутствуют зависимости между командами внутри группы и сведены к
минимуму зависимости между командами в разных группах.

Кроме того, на Эльбрусе регистровое окно сделано иначе, чем на
традиционных процессорных архитектурах. Обычно в архитектурах
используется ограниченное количество регистров общего назначения (как
правило, от нескольких десятков). Регистры применяются для хранения
промежуточных результатов вычислений, аргументов функций и возвращаемых
значений.

При вызове функции в архитектурах x86 и ARM используется стек вызовов:
перед переходом в функцию значения регистров, которые должны сохраниться
после возврата, сохраняются в памяти (стеке) с помощью инструкций
сохранения, а по завершении функции восстанавливаются из стека. В
процессе выполнения функция может модифицировать часть регистров.

В архитектуре Эльбрус механизм сохранения и восстановления регистров
посредством инструкций push и pop отсутствует. Процессор содержит пул из
256 регистров фиксированной разрядности (84 бита). Программно доступен
не весь пул: при входе в функцию происходит аппаратное выделение
определённого количества регистров, после чего процессор динамически
выделяет ей подмножество регистрационного пула, используемое
исключительно в рамках данной функции.

Кроме того, архитектура e2k имеет нестандартную модель стека. Эльбрус
использует три аппаратных стека, что повышает надёжность (исключает
переполнение стека), но усложняет перенос программного обеспечения,
рассчитанного на модель с единственным стеком. Процедурный стек (*PS*) и
стек связывающей информации (*PCS*) хранят данные о вызовах процедур и
возвратах; адрес возврата и контекст предыдущей процедуры размещаются
отдельно от пользовательского стека. Это усложняет операции раскрутки
стека (например, при обработке исключений). *PS* и *PCS* описываются базовым
адресом, размером и текущим смещением, хранимыми в 128-битных регистрах
*PSP* и *PCSP*, и тесно интегрированы с регистровым файлом через механизм
аппаратной подкачки и откачки регистров. В каждый момент данные этих
стеков находятся либо в памяти, либо в регистровом файле, оба стека
растут вверх. Пользовательский стек задаётся базовым адресом и размером,
его текущий указатель хранится в регистре *USD*. Он является классическим
стеком, растущим вниз, и не содержит данных процедурного стека и стека
связывающей информации.

Отсюда получается, что stackful корутины, которые требуют независимый
пользовательский стек, практически невозможны на архитектуре Эльбрус - 
архитектура использует аппаратные регистровые окна и несколько стеков, а
инструкции *push/pop* отсутствуют. Компилятор и рантайм не имеют
возможности произвольно сохранять и восстанавливать весь контекст
функции, как это делается на x86/ARM. Кроме того, контекст функции
частично управляется аппаратно, а не полностью доступен
программно, что делает невозможным создание полностью независимого
пользовательского стека для корутины. В результате можем рассматривать
только stackless корутины, где состояние сохраняется отдельно от стека.
Поэтому далее в статье под словом корутины будем иметь ввиду именно
stackless корутины.

Подробно про общую модель исполнения, регистры и окна на e2k смотреть
[здесь](https://habr.com/ru/companies/embox/articles/447704).

### Что корутины требуют от архитектуры?

Инструкции `yield`, `return` и `await` являются ключевыми при использовании
корутин, и обычно они требуют:

-   сохранения локальных переменных которые живут дольше точки
    приостановки;
-   сохранения состояния выполнения корутины в специальном фрейме, когда
    она приостанавливается;
-   сохранения текущей точки выполнения (*instruction pointer*);
-   восстановления сохранённого состояния при последующем возобновлении
    выполнения корутины.

Почему это работает на x86 и ARM, а на e2k возникают проблемы? Все
упирается в принцип *VLIW* на Эльбрус. Здесь мы сталкиваемся с целым рядом
проблем. Для начала, стоит сказать, что VLIW сильно полагается на
компилятор, которому бывает зачастую сложно эффективно распараллелить
операции между различными приостановками корутины, что снижает эффект
длинного слова. Кроме того, VLIW предпочитает предсказуемые определяемые
пути выполнения, а асинхронная природа корутин вносит трудно
оптимизируемую для VLIW-планировщика динамику. Также, компилятору на e2k
сложно генерировать эффективный VLIW-код для корутин, так как он должен
управлять как логикой переходов корутин, так и аппаратным
распаралеливанием, что требует более сложных анализов и оптимизаций, и в
целом сохранение состояния корутины дорого и не локально. Большое
количество специальных регистров на e2k также усложняет картину и
становится сложно корректно заморозить состояние корутины. Все это
приводит к заметному уменьшению производительности корутин на e2k, если
оставлять все как есть, особенно используя агрессивные оптимизации и
множество *co_await*.

## Эксперименты

В качестве первого шага имеет смысл запустить на e2k реальный код,
использующий библиотеку корутин, и проверить, как он ведёт себя на
практике. Это позволит убедиться, что выбранный подход вообще корректно
работает на данной архитектуре, без углубления в детали оптимизаций и
тонкости компилятора.

После этого полученные результаты можно сопоставить с выполнением того
же самого кода на стандартной архитектуре x86, где модель корутин давно
отлажена и хорошо изучена. Такое сравнение даёт базовую точку отсчёта:
становится понятно, какие различия обусловлены самой архитектурой e2k, а
какие реализацией библиотеки или поведением компилятора.

На этом этапе нас в первую очередь интересует не абсолютная
производительность, а корректность работы, предсказуемость поведения и
отсутствие архитектурно-зависимых эффектов, которые могли бы проявляться
только на e2k. Уже после этого можно переходить к более детальному
анализу - сравнению времени выполнения, характеристик сгенерированного
кода и т.д.

При этом будем использовать российский процессор **Эльбрус 8СВ** на
архитектуре e2k, разработанный компанией МЦСТ со следующими характеристиками:

 |  			Характеристика 		     |  			E8C2 		     |
|---|---|
|  			Производитель 		     |  			Elbrus-MCST 		     |
|  			Архитектура 		     |  			e2kv5 		     |
|  			Тип 			архитектуры 		        |  			VLIW 		     |
|  			Порядок 			байтов 		        |  			Little 			Endian 		        |
|  			Количество 			ядер 		        |  			8 			x 2 = 16 		        |
|  			Потоков 			на ядро 		        |  			1 		     |
|  			Базовая 			частота 		        |  			960.00 			МГц 		        |
|  			Максимальная 			частота 		        |  			1500.00 			МГц 		        |
|  			Кэш 			L1d 		        |  			1 			МБ (16 x 64 КБ) 		        |
|  			Кэш 			L1i 		        |  			2 			МБ (16 x 128 КБ) 		        |
|  			Кэш 			L2 		        |  			8 			МБ (16 x 512 КБ) 		        |
|  			Кэш 			L3 		        |  			32 			МБ (2 x 16 МБ) 		        |
|  			NUMA 			узлы 		        |  			2 		     |
|  			Оперативная 			память 		        |  			256 			ГБ 		        |

При компиляции тестовых примеров мы будем использовать современный
стандарт языка, поддерживающий корутины. Для C++ это будет стандарт
*C++20*, поскольку именно в нём появились полноценные корутины,
реализованные компилятором и не требующие ручного управления стеком.

Сборка будет выполняться с включённой оптимизацией `-O3`, чтобы оценить
поведение корутин в условиях, максимально приближённых к реальным.

Также важно отметить, что код будет компилироваться *без различных
расширений*, таких как inline asm или специфичных от конкретного ABI.
Это позволяет рассматривать результаты эксперимента как
репрезентативные, а не оптимизированные под конкретную платформу.

Такой подход даёт возможность сфокусироваться на различиях,
обусловленных архитектурой и бэкендом компилятора, а не деталями
конкретной реализации тестового кода.

Для начала стоит взять простейший пример с целью теста компиляции кода с
использованием корутин. Нужно убедиться, что код компилируется,
запускается и корректно переключает контекст. Для этого на первом
этапе можно взять простую [последовательность Фибоначчи](https://en.cppreference.com/w/cpp/language/coroutines.html), используя
компилятор **LCC-1.29.12** разработанный в компании МЦСТ, который является совместимым с
**gcc 11.3.0**:

```
#include <coroutine>
#include <cstdint>
#include <exception>
#include <iostream>
 
template<typename T>
struct Generator
{
    // The class name 'Generator' is our choice and it is not required for coroutine
    // magic. Compiler recognizes coroutine by the presence of 'co_yield' keyword.
    // You can use name 'MyGenerator' (or any other name) instead as long as you include#include <coroutine>
#include <cstdint>
#include <exception>
#include <iostream>
 
template<typename T>
struct Generator
{
    // The class name 'Generator' is our choice and it is not required for coroutine
    // magic. Compiler recognizes coroutine by the presence of 'co_yield' keyword.
    // You can use name 'MyGenerator' (or any other name) instead as long as you include
    // nested struct promise_type with 'MyGenerator get_return_object()' method.
    // (Note: It is necessary to adjust the declarations of constructors and destructors
    //  when renaming.)
 
    struct promise_type;
    using handle_type = std::coroutine_handle<promise_type>;
 
    struct promise_type // required
    {
        T value_;
        std::exception_ptr exception_;
 
        Generator get_return_object()
        {
            return Generator(handle_type::from_promise(*this));
        }
        std::suspend_always initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { return {}; }
        void unhandled_exception() { exception_ = std::current_exception(); } // saving
                                                                              // exception
 
        template<std::convertible_to<T> From> // C++20 concept
        std::suspend_always yield_value(From&& from)
        {
            value_ = std::forward<From>(from); // caching the result in promise
            return {};
        }
        void return_void() {}
    };
 
    handle_type h_;
 
    Generator(handle_type h) : h_(h) {}
    ~Generator() { h_.destroy(); }
    explicit operator bool()
    {
        fill(); // The only way to reliably find out whether or not we finished coroutine,
                // whether or not there is going to be a next value generated (co_yield)
                // in coroutine via C++ getter (operator () below) is to execute/resume
                // coroutine until the next co_yield point (or let it fall off end).
                // Then we store/cache result in promise to allow getter (operator() below
                // to grab it without executing coroutine).
        return !h_.done();
    }
    T operator()()
    {
        fill();
        full_ = false; // we are going to move out previously cached
                       // result to make promise empty again
        return std::move(h_.promise().value_);
    }
 
private:
    bool full_ = false;
 
    void fill()
    {
        if (!full_)
        {
            h_();
            if (h_.promise().exception_)
                std::rethrow_exception(h_.promise().exception_);
            // propagate coroutine exception in called context
 
            full_ = true;
        }
    }
};
 
Generator<std::uint64_t>
fibonacci_sequence(unsigned n)
{
    if (n == 0)
        co_return;
 
    if (n > 94)
        throw std::runtime_error("Too big Fibonacci sequence. Elements would overflow.");
 
    co_yield 0;
 
    if (n == 1)
        co_return;
 
    co_yield 1;
 
    if (n == 2)
        co_return;
 
    std::uint64_t a = 0;
    std::uint64_t b = 1;
 
    for (unsigned i = 2; i < n; ++i)
    {
        std::uint64_t s = a + b;
        co_yield s;
        a = b;
        b = s;
    }
}
 
int main()
{
    try
    {
        auto gen = fibonacci_sequence(10); // max 94 before uint64_t overflows
 
        for (int j = 0; gen; ++j)
            std::cout << "fib(" << j << ")=" << gen() << '\n';
    }
    catch (const std::exception& ex)
    {
        std::cerr << "Exception: " << ex.what() << '\n';
    }
    catch (...)
    {
        std::cerr << "Unknown exception.\n";
    }
}
```

Компиляция:

`g++ -std=c++20 -fcoroutines -o main main.cpp`

Результат:

```
lcc: "main.cpp", line 85: error #20: identifier "co_return" is undefined
          co_return;
          ^

lcc: "main.cpp", line 90: error #20: identifier "co_yield" is undefined
      co_yield 0;
      ^
```

Использование флага `-fcoroutines` также говорит нам о том, что LCC не
имеет поддержки корутин:

`lcc: error: unrecognized command line option "-fcoroutines"`

Таким образом, компилятор `LCC 1.29.14`, позиционируемый как
`gcc 11.3.0 compatible`, *не реализует поддержку корутин* ни в
одном из стандартных режимов языка C++:

-   отсутствует поддержка ключевых слов `co_await`, `co_yield`, `co_return`;
-   отсутствует поддержка `Coroutines TS (-fcoroutines-ts)`;
-   заголовок `<coroutine>` не имеют практического смысла без поддержки
    фронтенда.

Следующий компилятор, который можно использовать - clang-21, собранный
и запущенный нативно нашей компанией [НИЦ ЦТ](https://nicct.ru/) под архитектуру e2k:

```
clang version 21.1.3 (NICCT 21.1.3-2.cos

Target: e2k64-unknown-linux-gnu

Lccrt: lccopt r30.11.19.03

Thread model: posix

InstalledDir: /usr/bin
```

Для сравнения возьмём еще и известный компилятор clang-20 от *Unipro*:

```
Unipro (https://unipro.ru/) clang version 20.1.8 (fc6cfbd79839-1)

Target: e2k64-unknown-linux-gnu

Thread model: posix

InstalledDir: /usr/lib64/llvm-20/bin
```

Нам необходимо не только проверить корректность генерации кода, но и
посмотреть, есть ли заметные различия в поведении компилятора: времени
компиляции, качестве оптимизаций, размере генерируемого кода и в
производительности бинарников.

Компиляция:

`clang++ -std=c++20 -o main main.cpp`

Результат:

```
fib(0)=0
fib(1)=1
fib(2)=1
fib(3)=2
fib(4)=3
fib(5)=5
fib(6)=8
fib(7)=13
fib(8)=21
fib(9)=34
```

Обе версии clang выводят корректный результат, то есть clang-20 от
Unipro и clang-21 на архитектуре e2k как минимум
поддерживают C++20 корутины: программа успешно
компилируется, запускается и демонстрирует ожидаемый результат.

Стоит отметить, что:

-   используются стандартные ключевые слова
    `co_await`, `co_yield`, `co_return`;
-   применяется стандартный заголовок `<coroutine>` из стандарта C++20;
-   не используются специфические флаги или экспериментальные
    расширения;
-   код представлен без модификаций и интринсиков.

### Сравнение версий компиляторов

Отдельный интерес представляет вопрос, влияет ли более новая версия
компилятора clang на работу с корутинами и state-machine-кодом на e2k,
или же различия оказываются минимальными и упираются в особенности
бэкенда, а не версии компилятора.

Сравниваем скорость компиляции clang-20 и clang-21:

`time clang++ -std=c++20 -o main main.cpp`

clang-20:

```
real 0m3.067s
user 0m2.780s
sys 0m0.287s
```

clang-21:

```
real 0m2.997s
user 0m2.707s
sys 0m0.299s
```

Разница незначительная, в среднем на 80 милисек, что, вероятнее всего,
объясняется внутренними оптимизациями и улучшениями в более новой версии
LLVM, а не какими-либо принципиальными изменениями в механизме корутин.

Таким образом, в отличие от LCC 1.29.14, где поддержка корутин
отсутствует на уровне фронтенда, clang по крайней мере
предоставляет корутинную реализацию. Это позволяет
использовать stackless-корутины в соответствии со стандартом C++20 и
проводить сравнения далее.

Теперь нужно проверить поведение компилятора и сравнить его
с clang на архитектуре x86. В качестве
процессора используем **Intel Core i7-13620HВ**, имеющий 10 ядер и
16 потоков, типичный представитель x86-64 систем, поддерживающий
основные необходимые корутинные механизмы. В качестве дистрибутива
будем использовать *CentOS Stream 10*, потому что он,
во-первых, предоставляет одинаковую пользовательскую среду и версии
системных библиотек для разных архитектур, что позволяет изолировать
влияние компилятора и архитектуры от влияния дистрибутива, а во-вторых,
является базой для нашего дистрибутива на e2k [CollaborationOS](https://nicct.ru/produkty),
для которого был собран нативно clang-21. Так как на
CentOS 10 была обновлена версия *LLVM* и
*clang* до 21, для более точного эксперимента, а также с
учетом незначительной разницы в производительности и компиляции корутин
между clang-20 и clang-21, будем использовать
более новую версию clang-21 x86 и на e2k.

Замеряем время компиляции на e2k и x86.

На e2k:

`time clang++ -std=c++20 -o main main.cpp`

```
real 0m3.045s
user 0m2.750s
sys 0m0.300s
```

Здесь ориентируемся на показатель *real* - общее время, которое прошло
с момента запуска команды до её завершения.

То есть компиляция на e2k заняла около 3 секунд, из которых большая
часть приходится на сам clang, а не на системные операции.

На x86:

```
real 0m0,494s
user 0m0,311s
sys 0m0,064s
```

На x86 компиляция заняла всего 0.5 секунд. Видим, что на e2k результат в
8 раз медленее.

Причины этого заключаются, возможно, в том, что VLIW на e2k требует
более сложного планирования инструкций и анализа зависимостей, а clang
под e2k менее оптимизирован, чем x86-версия. Также не стоит забывать,
что *однопоточная производительность* Core i7-13620H существенно
выше, чем у Эльбрус 8СВ, а частоты, IPC и латентность памяти на x86
заметно [лучше](https://habr.com/ru/companies/icl_group/articles/501588).

Теперь замеряем размер бинарников.

На e2k:

`size main`

```
text data bss dec hex filename

67549 760 600 68909 10d2d main
```

Здесь:

*text* - код программы, включая сгенерированные state-machine корутин.

*data* - инициализированные глобальные переменные.

*bss* - неинициализированные глобальные переменные.

*dec* - суммарный размер в десятичной системе.

То есть бинарник на e2k занимает почти *68 Кб* кода и почти *69 Кб* в сумме.

На x86:

```
text data bss dec hex filename

16393 836 568 17797 4585 main
```

Суммарный размер всего около *18 Кб*, что в 4 раза меньше, чем на e2k. Это
объясняется архитектурой VLIW: один и тот же функционал требует большего
количества инструкций для упаковки параллельных операций.

Также генерируем промежуточное представление *LLVM IR* и делаем сравнение
diff (файл прилагается ниже):

`clang++ -std=c++20 -emit-llvm -S main.cpp -o main.ll`

В целом, изменения связаны в основном со спецификой работы компилятора,
например, на e2k добавляются строчки

```
+@_ZStL8__ioinit = internal global %"class.std::ios_base::Init" zeroinitializer, align 1 +@__dso_handle = external hidden global i8
```

Видно, что это стандартная инициализация потоков ввода-вывода, все
дополнительные глобальные объекты и конструкторы (`_ZStL8__ioinit`,
`_GLOBAL__sub_I_main.cpp`, `__cxa_atexit`) относятся к стандартной
библиотеке и инициализации потоков, а не к корутинам.

**Структура LLVM IR, coroutine frame и оптимизации практически
идентичны, различий в работе корутин нет.**

В итоге, можно сказать, что на архитектуре Эльбрус при компиляции
программ с использованием корутин нужно учитывать более длительное время
сборки и больший размер кода, но корутины в целом работают стандартно.

### Компиляция библиотеки libcoro

После тестирования базовых алгоритмов следующим шагом будет проверка
производительности на примере реальной библиотеки для работы с
корутинами [libcoro](https://github.com/jbaldwin/libcoro). Нужно
оценить, как на архитектуре e2k будет вести себя реальный проект и
сравнить с архитектурой x86. Мы рассматриваем эту библиотеку, так как
другая популярная библиотека [cppcoro](https://github.com/lewissbaker/cppcoro) не имеет поддержки e2k.

Склонируем библиотеку вместе с сабмодулем *c-ares*:

`git clone --recurse-submodules -j8 https://github.com/jbaldwin/libcoro.git`

Перед сборкой устанавливаем пакет *openssl-devel*.

Сборка и установка:

```
mkdir Release && cd Release
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ ..
cmake --build .
sudo cmake --install .
```

Обязательно следует добавить флаги использования компилятора clang
`-DCMAKE_C_COMPILER=clang` и опционально `-DCMAKE_CXX_COMPILER=clang++`,
так как некоторые под-проекты (например, c-ares) по умолчанию пытались
вызвать LCC и сборка падала с уже известными нам ошибками:

```
lcc: "/home/user/libcoro/src/detail/task_self_deleting.cpp", line 80: error #20:
          identifier "co_await" is undefined
      co_await user_task;
lcc: "/home/user/libcoro/src/detail/task_self_deleting.cpp", line 81: error #20:
          identifier "co_return" is undefined
      co_return;
      ^
```

После успешной сборки производим установку.

### Пример HTTP/TCP сервера на корутинах

Затем стоит протестировать работоспособность и производительность
библиотеки на архитектуре e2k. В качестве реального теста корутинов был
выбран TCP/HTTP-сервер на базе libcoro как один из примеров,
представленных библиотекой. В отличие от синтетических примеров, сервер
обрабатывает реальные сетевые соединения, используя неблокирующий
ввод-вывод, обрабатывает каждого клиента в отдельной корутине и не
создает дополнительных потоков на соединение. Сервер построен вокруг
*coro::io_scheduler* в качестве *event loop*, корутина выполняет роль
клиента, не используется *callback* и *std::thread*. Scheduler запускает
корутину, ожидающую входящие соединения, принимает запрос клиента и
затем порождает отдельную корутину для обработки соединения. Код
представлен ниже.

```
#include <coro/coro.hpp>

auto main() -> int
{
    auto make_http_200_ok_server = [](std::unique_ptr<coro::io_scheduler>& scheduler) -> coro::task<void>
    {
        auto make_on_connection_task = [](coro::net::tcp::client client) -> coro::task<void>
        {
            std::string response = "HTTP/1.1 200 OK\r\nContent-Length: 0\r\nConnection: keep-alive\r\n\r\n";
            std::string buf(1024, '\0');

            while (true)
            {
                // Wait for data to be available to read.
                co_await client.poll(coro::poll_op::read);
                auto [rstatus, rspan] = client.recv(buf);
                switch (rstatus)
                {
                    case coro::net::recv_status::ok:
                        // Make sure the client socket can be written to.
                        co_await client.poll(coro::poll_op::write);
                        client.send(std::span<const char>{response});
                        break;
                    case coro::net::recv_status::would_block:
                        break;
                    case coro::net::recv_status::closed:
                    default:
                        co_return;
                }
            }
        };

        coro::net::tcp::server server{scheduler, coro::net::tcp::server::options{.port = 8888}};

        while (true)
        {
            // Wait for a new connection.
            auto pstatus = co_await server.poll();
            switch (pstatus)
            {
                case coro::poll_status::read:
                {
                    auto client = server.accept();
                    if (client.socket().is_valid())
                    {
                        scheduler->spawn_detached(make_on_connection_task(std::move(client)));
                    } // else report error or something if the socket was invalid or could not be accepted.
                }
                break;
                case coro::poll_status::write:
                case coro::poll_status::error:
                case coro::poll_status::closed:
                case coro::poll_status::timeout:
                default:
                    co_return;
            }
        }

        co_return;
    };

    std::vector<std::unique_ptr<coro::io_scheduler>> schedulers{};
    std::vector<coro::task<void>>                    workers{};

    const std::size_t count = std::thread::hardware_concurrency();

    schedulers.reserve(count);
    workers.reserve(count);

    for (size_t i = 0; i < count; ++i)
    {
        auto& scheduler = schedulers.emplace_back(coro::io_scheduler::make_unique(coro::io_scheduler::options{
            .execution_strategy = coro::io_scheduler::execution_strategy_t::process_tasks_inline}));

        workers.emplace_back(scheduler->schedule(make_http_200_ok_server(scheduler)));
    }

    coro::sync_wait(coro::when_all(std::move(workers)));
}
```

Компиляция:

`clang++ -std=c++20 coro_http_200_ok_server.cpp -lcoro -DLIBCORO_FEATURE_NETWORKING -o coro_http_200_ok_server`

Обязательно добавляем флаг `-DLIBCORO_FEATURE_NETWORKING` для включения
сетевого функционала библиотеки, который по умолчанию отключен.

Если видим ошибку *'ares.h' file not found*, устанавливаем пакет
*c-ares-devel*.

В итоге запускаем сервер, проверяем его работу. Сервер начинает слушать по порту 8888.

Проверяем соединение:


`curl -v http://127.0.0.1:8888/`

```
*   Trying 127.0.0.1:8888...
* Connected to 127.0.0.1 (127.0.0.1) port 8888 (#0)
> GET / HTTP/1.1
> Host: 127.0.0.1:8888
> User-Agent: curl/7.76.1
> Accept: */*
>
* Mark bundle as not supporting multiuse
< HTTP/1.1 200 OK
< Content-Length: 0
< Connection: keep-alive
<
* Connection #0 to host 127.0.0.1 left intact
```

Соединение успешно.

Для корректной оценки производительности будем использовать инструмент
**wrk**, корректно работающий с асинхронными, а также основанными на
корутинах серверами, так как при использовании ApacheBench сервер с keep-alive
соединениями демонстрирует таймауты со стороны клиента, что связано с
особенностями ApacheBench на e2k. Клоним и собираем, установив перед
этим *perl-FindBin* и *perl-File-Compare*:

```
git clone https://github.com/wg/wrk.git
cd wrk
make
```

Установка:

`sudo cp wrk /usr/local/bin`

Проверяем нагрузку сервера.

На e2k:

`wrk -t4 -c200 -d30s http://127.0.0.1:8888/`

```
Running 30s test @ http://127.0.0.1:8888/
  4 threads and 200 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.32ms  804.45us  40.11ms   96.58%
    Req/Sec    19.93k   563.89    21.03k    85.08%
  2384730 requests in 30.08s, 141.00MB read
Requests/sec:  79266.48
Transfer/sec:      4.69MB
```

Здесь:

-   4 worker threads - генераторы нагрузки;
-   200 одновременных соединений;
-   30 секунд непрерывной работы;
-   keep-alive включён.

Видим, что при такой нагрузке, как 200 одновременных соединений и 4
генератора нагрузки, сервер на libcoro показал около 80 тысяч запросов в
секунду при средней задержке 1.32 мс. Результаты стабильны на протяжении
всего теста и не демонстрируют деградации со временем, что указывает на
корректную работу event loop и корутинного планировщика. Распределение
задержек остается предсказуемым, что важно для серверных приложений.

На x86:

```
Running 30s test @ http://127.0.0.1:8888/
  4 threads and 200 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   364.13us  578.50us  16.20ms   91.77%
    Req/Sec   157.26k    46.03k  228.67k    46.50%
  18776185 requests in 30.01s, 1.08GB read
Requests/sec: 625591.69
Transfer/sec:     36.99MB
```

Здесь мы видим, что при идентичной нагрузке сервер показывает 625 тысяч
запросов в секунду при средней задержке 364 мкс, что дает
восьмикратное преимущество по пропускной способности и и примерно в 3 с
половиной раза меньшую задержку по сравнению с e2k, опять же по причине
более высокой однопоточной производительности, частоты процессора и
меньшей эффективности VLIW-архитектуры для решения серверных задач.

Однако, хоть производительность в серверных сценариях на архитектуре
Эльбрус и уступает в разы x86-платформам, не было замечено деградации
производительности, больших задержек под нагрузкой и нестабильного
поведения планировщика, что говорит о достаточно корректной работе
stackless-корутин в серверных задачах.

Далее стоит оценить показатели при активной нагрузке сервера через
профилировщик perf для оценки накладных расходов корутин на e2k.
Нагрузку подаем также через wrk, используя 200 одновременных соединений.
В первом окне запускаем perf, предварительно получая *pid* сервера:

`perf stat -p 516880 -d`

Во втором окне запускаем нагрузку:

`wrk -t4 -c200 -d30s http://127.0.0.1:8888`

Через 30 секунд получаем результаты профилировщика на процессоре Эльбрус
8СВ;

```
 Performance counter stats for process id '516880':

         167006.65 msec task-clock:u              #    3.252 CPUs utilized
                 0      context-switches:u        #    0.000 K/sec
                 0      cpu-migrations:u          #    0.000 K/sec
              1453      page-faults:u             #    0.009 K/sec
       25954043811      cycles:u                  #    0.155 GHz
        9388012974      instructions:u            #    0.36  insn per cycle
   <not supported>      branches:u
   <not supported>      branch-misses:u
   <not supported>      L1-dcache-loads:u
   <not supported>      L1-dcache-load-misses:u
   <not supported>      LLC-loads:u
   <not supported>      LLC-load-misses:u

      51.355712726 seconds time elapsed
```

По результатам профилирования видим, что

-   3.252 CPUs utilized - сервер использует 3-4 ядра;
-   context-switches: 0 и cpu-migrations: 0 - нет переключения
    потоков;
-   page-faults: 1453 за 51.355712726 seconds time elapsed -
    аппаратные исключения, низкий уровень активности;
-   25954043811 cycles и 9388012974 instructions, отсюда IPC = 0.36, что
    является слабым результатом, но довольно ожидаемо, учитывая характер
    нагрузки и специфику сетевого кода на e2k.
-   Часть аппаратных счётчиков (*branch-misses*, *cache-misses*) недоступна
    на данном процессоре.

На x86:

```
    55 537 268 370      task-clock:u                     #    1,754 CPUs utili
zed
                 0      context-switches:u               #    0,000 /sec
                 0      cpu-migrations:u                 #    0,000 /sec
                 0      page-faults:u                    #    0,000 /sec
   <not supported>      cycles:u

      31,665295787 seconds time elapsed
```

Видим здесь также отсутствие *context switches*, *cpu migrations*, а также
полное отсутствие page faults, в отличии от профилирования на e2k, что
говорит нам скорее о более высокой чувствительности к управлению памяти
на процессоре Эльбрус, то есть данные различия говорят скорее об
особенности архитектуры, а не логике сервера или корутин.

К сожалению, использование метрик cycles и instructions не
поддерживается на гибридном процессоре Intel Core i7-13620H, так что
напрямую сравнить результат с IPC на e2k, который был равен 0,36,
нельзя, и стоит опираться на показатели task-clock и CPUs utilized. В
целом сервер на x86 показывает большую производительность на x86, что
неудивительно.

Обе архитектуры подтверждают полностью user-space модель планирования
корутин. На архитектуре Эльбрус, несмотря на относительно низкий IPC
0,36, сервер демонстрирует достаточную пропускную способность 80 тыс.
запросов в секунду, что указывает на отсутствие существенных накладных
расходов, связанных с использованием корутин.

## Итоги

В данной статье было рассмотрено использование stackless-корутин на
архитектуре Эльбрус и проведено сравнение с их поведением на архитектуре
x86-64. В целом, компиляторы clang-20 и clang-21 предоставляют поддержку корутин стандарта C++20 на e2k,
в отличие от компилятора LCC-1.29.14 от
компании МЦСТ, использующий стандарт C++20.
Приведенные в статье примеры показали, что в целом
stackless-корутины могут запускаться и выполняться на
архитектуре Эльбрус, но там, где критически важна максимальная
пропускная способность, приоритет будет у архитектуры x86-64.
На архитектуре e2k были замечены потери
производительности, которые, однако, скорее связаны с самой
архитектурой и процессорами Эльбрус, а не с логикой корутин.
Кроме того, stackless-корутины остаются единственным вариантом
применения на архитектуре Эльбрус, а stackful-корутины
практически невозможны и сложны в реализации ввиду специфики
архитектуры VLIW.



## Полезные ссылки

1. https://www.altlinux.org/Эльбрус/портирование
2. https://habr.com/ru/companies/rostelecom/articles/562858/
3. https://habr.com/ru/articles/908386/
4. http://mcst.ru/files/5ed39a/dd0cd8/50506b/000000/elbrus_prog_2020-05-30.pdf
5. https://habr.com/ru/companies/icl_group/articles/501588/
6. https://habr.com/ru/companies/nic_ct/articles/917490/

